{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install d2l","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-07T07:51:09.480093Z","iopub.execute_input":"2023-11-07T07:51:09.480470Z","iopub.status.idle":"2023-11-07T07:51:41.177694Z","shell.execute_reply.started":"2023-11-07T07:51:09.480436Z","shell.execute_reply":"2023-11-07T07:51:41.176610Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting d2l\n  Downloading d2l-1.0.3-py3-none-any.whl (111 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting jupyter==1.0.0 (from d2l)\n  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\nRequirement already satisfied: numpy==1.23.5 in /opt/conda/lib/python3.10/site-packages (from d2l) (1.23.5)\nRequirement already satisfied: matplotlib==3.7.2 in /opt/conda/lib/python3.10/site-packages (from d2l) (3.7.2)\nRequirement already satisfied: matplotlib-inline==0.1.6 in /opt/conda/lib/python3.10/site-packages (from d2l) (0.1.6)\nRequirement already satisfied: requests==2.31.0 in /opt/conda/lib/python3.10/site-packages (from d2l) (2.31.0)\nCollecting pandas==2.0.3 (from d2l)\n  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting scipy==1.10.1 (from d2l)\n  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: notebook in /opt/conda/lib/python3.10/site-packages (from jupyter==1.0.0->d2l) (6.5.4)\nRequirement already satisfied: qtconsole in /opt/conda/lib/python3.10/site-packages (from jupyter==1.0.0->d2l) (5.4.4)\nRequirement already satisfied: jupyter-console in /opt/conda/lib/python3.10/site-packages (from jupyter==1.0.0->d2l) (6.6.3)\nRequirement already satisfied: nbconvert in /opt/conda/lib/python3.10/site-packages (from jupyter==1.0.0->d2l) (6.4.5)\nRequirement already satisfied: ipykernel in /opt/conda/lib/python3.10/site-packages (from jupyter==1.0.0->d2l) (6.23.3)\nRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (from jupyter==1.0.0->d2l) (7.7.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.2->d2l) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.2->d2l) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.2->d2l) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.2->d2l) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.2->d2l) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.2->d2l) (9.5.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.2->d2l) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.7.2->d2l) (2.8.2)\nRequirement already satisfied: traitlets in /opt/conda/lib/python3.10/site-packages (from matplotlib-inline==0.1.6->d2l) (5.9.0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3->d2l) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3->d2l) (2023.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests==2.31.0->d2l) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests==2.31.0->d2l) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests==2.31.0->d2l) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests==2.31.0->d2l) (2023.7.22)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l) (1.16.0)\nRequirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter==1.0.0->d2l) (0.1.3)\nRequirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter==1.0.0->d2l) (1.6.7)\nRequirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter==1.0.0->d2l) (8.14.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter==1.0.0->d2l) (7.4.9)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter==1.0.0->d2l) (5.3.1)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter==1.0.0->d2l) (1.5.6)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter==1.0.0->d2l) (5.9.3)\nRequirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter==1.0.0->d2l) (25.1.0)\nRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter==1.0.0->d2l) (6.3.2)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->jupyter==1.0.0->d2l) (0.2.0)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.6.5)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.0.7)\nRequirement already satisfied: prompt-toolkit>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from jupyter-console->jupyter==1.0.0->d2l) (3.0.38)\nRequirement already satisfied: pygments in /opt/conda/lib/python3.10/site-packages (from jupyter-console->jupyter==1.0.0->d2l) (2.15.1)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\nRequirement already satisfied: jinja2>=2.4 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->d2l) (3.1.2)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->d2l) (0.2.2)\nRequirement already satisfied: nbformat>=4.4 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->d2l) (5.9.0)\nRequirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->d2l) (0.4)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->d2l) (6.0.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.0)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->d2l) (0.6.0)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->d2l) (4.12.2)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->d2l) (0.5.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter==1.0.0->d2l) (2.1.3)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter==1.0.0->d2l) (21.3.0)\nRequirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter==1.0.0->d2l) (1.8.2)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter==1.0.0->d2l) (0.17.1)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter==1.0.0->d2l) (0.17.0)\nRequirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter==1.0.0->d2l) (1.0.0)\nRequirement already satisfied: qtpy>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from qtconsole->jupyter==1.0.0->d2l) (2.4.0)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.2.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.18.2)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.6.2)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (4.8.0)\nRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter==1.0.0->d2l) (3.10.0)\nRequirement already satisfied: jupyter-server>=1.8 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (2.6.0)\nRequirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.2.3)\nRequirement already satisfied: fastjsonschema in /opt/conda/lib/python3.10/site-packages (from nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (2.17.1)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (4.17.3)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter==1.0.0->d2l) (0.2.6)\nRequirement already satisfied: ptyprocess in /opt/conda/lib/python3.10/site-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l) (0.7.0)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l) (21.2.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l) (2.3.2.post1)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.8.3)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (23.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (0.19.3)\nRequirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (3.7.0)\nRequirement already satisfied: jupyter-events>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.6.3)\nRequirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.4.4)\nRequirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (6.5.0)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.6.0)\nRequirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (1.15.1)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (1.2.0)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (2.2.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.2.2)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.1.1)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (2.21)\nRequirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (2.0.7)\nRequirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (6.0)\nRequirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.1.1)\nRequirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (1.5.1)\nRequirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (2.0)\nRequirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (1.3.0)\nRequirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (1.13)\nRequirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter==1.0.0->d2l) (1.2.3)\nInstalling collected packages: scipy, pandas, jupyter, d2l\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.11.2\n    Uninstalling scipy-1.11.2:\n      Successfully uninstalled scipy-1.11.2\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.0.2\n    Uninstalling pandas-2.0.2:\n      Successfully uninstalled pandas-2.0.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nbeatrix-jupyterlab 2023.621.222118 requires jupyter-server~=1.16, but you have jupyter-server 2.6.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.10.1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed d2l-1.0.3 jupyter-1.0.0 pandas-2.0.3 scipy-1.10.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install torchinfo","metadata":{"execution":{"iopub.status.busy":"2023-11-07T07:51:41.180227Z","iopub.execute_input":"2023-11-07T07:51:41.181212Z","iopub.status.idle":"2023-11-07T07:51:52.521855Z","shell.execute_reply.started":"2023-11-07T07:51:41.181137Z","shell.execute_reply":"2023-11-07T07:51:52.520731Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchinfo in /opt/conda/lib/python3.10/site-packages (1.8.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom d2l import torch as d2l","metadata":{"execution":{"iopub.status.busy":"2023-11-07T07:51:52.523237Z","iopub.execute_input":"2023-11-07T07:51:52.523545Z","iopub.status.idle":"2023-11-07T07:51:55.999017Z","shell.execute_reply.started":"2023-11-07T07:51:52.523516Z","shell.execute_reply":"2023-11-07T07:51:55.997803Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"<frozen importlib._bootstrap>:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n","output_type":"stream"}]},{"cell_type":"code","source":"raw_data = pd.read_csv('/kaggle/input/weiboedit/weibo_xiugaishuju.csv', names=['label','review'], header=None)\nraw_data","metadata":{"execution":{"iopub.status.busy":"2023-11-07T07:51:56.001037Z","iopub.execute_input":"2023-11-07T07:51:56.002143Z","iopub.status.idle":"2023-11-07T07:51:56.232454Z","shell.execute_reply.started":"2023-11-07T07:51:56.002094Z","shell.execute_reply":"2023-11-07T07:51:56.230560Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       label                                             review\n0          1  战疫风警线阻隔疫情，但不阻隔警民鱼水情近期，边防港航分局杨浦水上派出所接到辖区单位求助，厂区...\n1          1  我身边的大白们佛山公安在行动，重点行业场所巡查战疫剪影连日来，高明分局组织警力对全区旅馆业、...\n2          1                    疫情防控这么晚还在工作的医务人员辛苦啦北京北京友谊医院西城院区\n3          1                                   疫情防控人人有责疫情防控人人有责\n4          1                  疫情快快消退希望家人们都平安归来梅河口11000名逆行勇士奔赴长春\n...      ...                                                ...\n30429      0  2020年萨斯疫情爆发，中国的专家们在毫无经验的情况下，只用了5个月就找到了直接传染源果子狸...\n30430      0  月8日1006，中国南方航空多伦多广州航班顺利降落在广州白云国际机场，这是乙类乙管总体方案和...\n30431      0      疫情防控关于毒株，张伯礼最新解读详情点击链接如果出现再次感染，一定要首先分清复阳与二次感染\n30432      1  疫情自从国家开放以来不知去死了多少人，让人泪目，可今天看见申明重开国境的大门，这是不顾国人安...\n30433      1                                        疫情后第一天常态化上班\n\n[30434 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>战疫风警线阻隔疫情，但不阻隔警民鱼水情近期，边防港航分局杨浦水上派出所接到辖区单位求助，厂区...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>我身边的大白们佛山公安在行动，重点行业场所巡查战疫剪影连日来，高明分局组织警力对全区旅馆业、...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>疫情防控这么晚还在工作的医务人员辛苦啦北京北京友谊医院西城院区</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>疫情防控人人有责疫情防控人人有责</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>疫情快快消退希望家人们都平安归来梅河口11000名逆行勇士奔赴长春</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30429</th>\n      <td>0</td>\n      <td>2020年萨斯疫情爆发，中国的专家们在毫无经验的情况下，只用了5个月就找到了直接传染源果子狸...</td>\n    </tr>\n    <tr>\n      <th>30430</th>\n      <td>0</td>\n      <td>月8日1006，中国南方航空多伦多广州航班顺利降落在广州白云国际机场，这是乙类乙管总体方案和...</td>\n    </tr>\n    <tr>\n      <th>30431</th>\n      <td>0</td>\n      <td>疫情防控关于毒株，张伯礼最新解读详情点击链接如果出现再次感染，一定要首先分清复阳与二次感染</td>\n    </tr>\n    <tr>\n      <th>30432</th>\n      <td>1</td>\n      <td>疫情自从国家开放以来不知去死了多少人，让人泪目，可今天看见申明重开国境的大门，这是不顾国人安...</td>\n    </tr>\n    <tr>\n      <th>30433</th>\n      <td>1</td>\n      <td>疫情后第一天常态化上班</td>\n    </tr>\n  </tbody>\n</table>\n<p>30434 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nraw_data","metadata":{"execution":{"iopub.status.busy":"2023-11-07T07:51:56.235484Z","iopub.execute_input":"2023-11-07T07:51:56.235785Z","iopub.status.idle":"2023-11-07T07:51:56.246693Z","shell.execute_reply.started":"2023-11-07T07:51:56.235760Z","shell.execute_reply":"2023-11-07T07:51:56.245651Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       label                                             review\n0          1  战疫风警线阻隔疫情，但不阻隔警民鱼水情近期，边防港航分局杨浦水上派出所接到辖区单位求助，厂区...\n1          1  我身边的大白们佛山公安在行动，重点行业场所巡查战疫剪影连日来，高明分局组织警力对全区旅馆业、...\n2          1                    疫情防控这么晚还在工作的医务人员辛苦啦北京北京友谊医院西城院区\n3          1                                   疫情防控人人有责疫情防控人人有责\n4          1                  疫情快快消退希望家人们都平安归来梅河口11000名逆行勇士奔赴长春\n...      ...                                                ...\n30429      0  2020年萨斯疫情爆发，中国的专家们在毫无经验的情况下，只用了5个月就找到了直接传染源果子狸...\n30430      0  月8日1006，中国南方航空多伦多广州航班顺利降落在广州白云国际机场，这是乙类乙管总体方案和...\n30431      0      疫情防控关于毒株，张伯礼最新解读详情点击链接如果出现再次感染，一定要首先分清复阳与二次感染\n30432      1  疫情自从国家开放以来不知去死了多少人，让人泪目，可今天看见申明重开国境的大门，这是不顾国人安...\n30433      1                                        疫情后第一天常态化上班\n\n[30434 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>战疫风警线阻隔疫情，但不阻隔警民鱼水情近期，边防港航分局杨浦水上派出所接到辖区单位求助，厂区...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>我身边的大白们佛山公安在行动，重点行业场所巡查战疫剪影连日来，高明分局组织警力对全区旅馆业、...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>疫情防控这么晚还在工作的医务人员辛苦啦北京北京友谊医院西城院区</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>疫情防控人人有责疫情防控人人有责</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>疫情快快消退希望家人们都平安归来梅河口11000名逆行勇士奔赴长春</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30429</th>\n      <td>0</td>\n      <td>2020年萨斯疫情爆发，中国的专家们在毫无经验的情况下，只用了5个月就找到了直接传染源果子狸...</td>\n    </tr>\n    <tr>\n      <th>30430</th>\n      <td>0</td>\n      <td>月8日1006，中国南方航空多伦多广州航班顺利降落在广州白云国际机场，这是乙类乙管总体方案和...</td>\n    </tr>\n    <tr>\n      <th>30431</th>\n      <td>0</td>\n      <td>疫情防控关于毒株，张伯礼最新解读详情点击链接如果出现再次感染，一定要首先分清复阳与二次感染</td>\n    </tr>\n    <tr>\n      <th>30432</th>\n      <td>1</td>\n      <td>疫情自从国家开放以来不知去死了多少人，让人泪目，可今天看见申明重开国境的大门，这是不顾国人安...</td>\n    </tr>\n    <tr>\n      <th>30433</th>\n      <td>1</td>\n      <td>疫情后第一天常态化上班</td>\n    </tr>\n  </tbody>\n</table>\n<p>30434 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\nfor train_index,test_index in split.split(raw_data['review'],raw_data['label']):\n    train_set = raw_data.iloc[train_index, :]\n    test_set = raw_data.iloc[test_index, :]\ntrain_set\ntest_set","metadata":{"execution":{"iopub.status.busy":"2023-11-07T07:51:56.248066Z","iopub.execute_input":"2023-11-07T07:51:56.248527Z","iopub.status.idle":"2023-11-07T07:51:56.731635Z","shell.execute_reply.started":"2023-11-07T07:51:56.248501Z","shell.execute_reply":"2023-11-07T07:51:56.730726Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       label                                             review\n26423      1  十二月的第十九天，依旧喜欢林允儿。昨天十一点多被妈妈喊醒去做饭，就是说这个逼疫情，烦死了。下...\n1154       1  对节白蜡女孩在百年对节白蜡树下，双手合十，许下美好的心愿，当即出现两道神光。惟愿疫情消失，别...\n6655       1  戴口罩很重要在当前疫情防控形势下，戴口罩依然是公众做好个人防护的重要手段！戴好口罩到底能在多...\n7522       0  昨天有个省区市出现病例，前一日是个。总数升至100。广西疫情重点在崇左。甘肃疫情重点在临夏州...\n3102       1  今天下班时间凌晨50，走在路上好冷，感觉冬天要来了。气候的反常，疫情的反常，活着就好！今年的...\n...      ...                                                ...\n21416      1                            希望疫情早日结束。想回家撒撒娇想见外公外婆……\n14461      0   哈尔滨疫情哈尔滨有高风险和中风险地区，但我没去过这些地区，还是绿码，是不是不算去过中高风险地区啊\n22241      0                          疫情啥时候能彻底结束啊我这仓库70的羽绒服等着卖呢\n22872      0                广州疫情什么时候能让我出去晒晒太阳看看海，刚找到工作又快要失业了。广州\n21339      0  阵亡号没发出来的草稿，目前看确实如此，自由总归是需要付出一些代价的。我现在出门口罩都升级成9...\n\n[24347 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26423</th>\n      <td>1</td>\n      <td>十二月的第十九天，依旧喜欢林允儿。昨天十一点多被妈妈喊醒去做饭，就是说这个逼疫情，烦死了。下...</td>\n    </tr>\n    <tr>\n      <th>1154</th>\n      <td>1</td>\n      <td>对节白蜡女孩在百年对节白蜡树下，双手合十，许下美好的心愿，当即出现两道神光。惟愿疫情消失，别...</td>\n    </tr>\n    <tr>\n      <th>6655</th>\n      <td>1</td>\n      <td>戴口罩很重要在当前疫情防控形势下，戴口罩依然是公众做好个人防护的重要手段！戴好口罩到底能在多...</td>\n    </tr>\n    <tr>\n      <th>7522</th>\n      <td>0</td>\n      <td>昨天有个省区市出现病例，前一日是个。总数升至100。广西疫情重点在崇左。甘肃疫情重点在临夏州...</td>\n    </tr>\n    <tr>\n      <th>3102</th>\n      <td>1</td>\n      <td>今天下班时间凌晨50，走在路上好冷，感觉冬天要来了。气候的反常，疫情的反常，活着就好！今年的...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>21416</th>\n      <td>1</td>\n      <td>希望疫情早日结束。想回家撒撒娇想见外公外婆……</td>\n    </tr>\n    <tr>\n      <th>14461</th>\n      <td>0</td>\n      <td>哈尔滨疫情哈尔滨有高风险和中风险地区，但我没去过这些地区，还是绿码，是不是不算去过中高风险地区啊</td>\n    </tr>\n    <tr>\n      <th>22241</th>\n      <td>0</td>\n      <td>疫情啥时候能彻底结束啊我这仓库70的羽绒服等着卖呢</td>\n    </tr>\n    <tr>\n      <th>22872</th>\n      <td>0</td>\n      <td>广州疫情什么时候能让我出去晒晒太阳看看海，刚找到工作又快要失业了。广州</td>\n    </tr>\n    <tr>\n      <th>21339</th>\n      <td>0</td>\n      <td>阵亡号没发出来的草稿，目前看确实如此，自由总归是需要付出一些代价的。我现在出门口罩都升级成9...</td>\n    </tr>\n  </tbody>\n</table>\n<p>24347 rows × 2 columns</p>\n</div>"},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       label                                             review\n6311       1  结婚赶上全员核酸新人给大白发喜糖收获满满的祝福7月8日，河南栾川，一对新人结婚当天遇上全员核...\n20447      1  黄景瑜这人事业心比粉丝强多了。自己知道演梁牧泽的后期因为疫情关了一个月吃胖到80斤可是脸完全...\n13609      0                           西藏抗疫山南市高风险区清零疫情防控格桑花开新西藏\n30013      0  我爷爷奶奶真好笑上学期奶奶跟我打电话控诉爷爷拔她，因为她每天跟姐妹的活动太多了，我爷爷没啥活...\n10267      0     目前疫情防控形势依然严峻复杂，出行请做好个人防护，同时也要做好防火工作哦！更多知识，戳图了解\n...      ...                                                ...\n21039      0                             宁波疫情休个假又被背刺了还是安心在家看阿瑟吧\n23174      1  日常广州疫情有朋友问，两个娃居家，学习怎么抓，没人管能不能自觉学习？还是可以的。关键要做好计...\n3867       1  收到了新的健身服！我可太开心了！！！！！是疫情期间最想收到的快递加上姨妈开始轻虐我，迫不及待...\n2579       1                            运动完真快乐呀疫情在家坚持运动坚持早起拼命练习\n30396      1  等底迪婚礼返图等睡了的亲姐姐本人因为疫情没能参加订婚又因为小兔崽子没能参加婚礼没能去现场一整...\n\n[6087 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6311</th>\n      <td>1</td>\n      <td>结婚赶上全员核酸新人给大白发喜糖收获满满的祝福7月8日，河南栾川，一对新人结婚当天遇上全员核...</td>\n    </tr>\n    <tr>\n      <th>20447</th>\n      <td>1</td>\n      <td>黄景瑜这人事业心比粉丝强多了。自己知道演梁牧泽的后期因为疫情关了一个月吃胖到80斤可是脸完全...</td>\n    </tr>\n    <tr>\n      <th>13609</th>\n      <td>0</td>\n      <td>西藏抗疫山南市高风险区清零疫情防控格桑花开新西藏</td>\n    </tr>\n    <tr>\n      <th>30013</th>\n      <td>0</td>\n      <td>我爷爷奶奶真好笑上学期奶奶跟我打电话控诉爷爷拔她，因为她每天跟姐妹的活动太多了，我爷爷没啥活...</td>\n    </tr>\n    <tr>\n      <th>10267</th>\n      <td>0</td>\n      <td>目前疫情防控形势依然严峻复杂，出行请做好个人防护，同时也要做好防火工作哦！更多知识，戳图了解</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>21039</th>\n      <td>0</td>\n      <td>宁波疫情休个假又被背刺了还是安心在家看阿瑟吧</td>\n    </tr>\n    <tr>\n      <th>23174</th>\n      <td>1</td>\n      <td>日常广州疫情有朋友问，两个娃居家，学习怎么抓，没人管能不能自觉学习？还是可以的。关键要做好计...</td>\n    </tr>\n    <tr>\n      <th>3867</th>\n      <td>1</td>\n      <td>收到了新的健身服！我可太开心了！！！！！是疫情期间最想收到的快递加上姨妈开始轻虐我，迫不及待...</td>\n    </tr>\n    <tr>\n      <th>2579</th>\n      <td>1</td>\n      <td>运动完真快乐呀疫情在家坚持运动坚持早起拼命练习</td>\n    </tr>\n    <tr>\n      <th>30396</th>\n      <td>1</td>\n      <td>等底迪婚礼返图等睡了的亲姐姐本人因为疫情没能参加订婚又因为小兔崽子没能参加婚礼没能去现场一整...</td>\n    </tr>\n  </tbody>\n</table>\n<p>6087 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#使用过采样\nfrom imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=42)\ntrain_set_balanced_over, _ = ros.fit_resample(train_set, train_set['label'])\ntrain_set_balanced_over\n#使用欠采样\nfrom imblearn.under_sampling import RandomUnderSampler\nrus = RandomUnderSampler(random_state=42)\ntrain_set_balanced_under, _ = rus.fit_resample(train_set, train_set['label'])\ntrain_set_balanced_under","metadata":{"execution":{"iopub.status.busy":"2023-11-07T07:51:56.732751Z","iopub.execute_input":"2023-11-07T07:51:56.733028Z","iopub.status.idle":"2023-11-07T07:51:57.162500Z","shell.execute_reply.started":"2023-11-07T07:51:56.733003Z","shell.execute_reply":"2023-11-07T07:51:57.161622Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"       label                                             review\n0          1  十二月的第十九天，依旧喜欢林允儿。昨天十一点多被妈妈喊醒去做饭，就是说这个逼疫情，烦死了。下...\n1          1  对节白蜡女孩在百年对节白蜡树下，双手合十，许下美好的心愿，当即出现两道神光。惟愿疫情消失，别...\n2          1  戴口罩很重要在当前疫情防控形势下，戴口罩依然是公众做好个人防护的重要手段！戴好口罩到底能在多...\n3          0  昨天有个省区市出现病例，前一日是个。总数升至100。广西疫情重点在崇左。甘肃疫情重点在临夏州...\n4          1  今天下班时间凌晨50，走在路上好冷，感觉冬天要来了。气候的反常，疫情的反常，活着就好！今年的...\n...      ...                                                ...\n25423      1                                          深圳疫情防控疫情退\n25424      1  最近很多人都受到了感染，感染后的症状轻重各别，有些人觉得比较轻松就度过去了，有些人却经历了高...\n25425      1  快递驿站站长，武汉疫情期间的送菜英雄，同时他还收养了0多只流浪猫。春节期间他的快递驿站不打烊...\n25426      1                                            懒觉疫情刮红赛\n25427      1  三年前快过年的时候正赶上武汉疫情兴起武汉封城，很多人逃到岳阳。当时一家子的人都笑我说我紧张兮...\n\n[25428 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>十二月的第十九天，依旧喜欢林允儿。昨天十一点多被妈妈喊醒去做饭，就是说这个逼疫情，烦死了。下...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>对节白蜡女孩在百年对节白蜡树下，双手合十，许下美好的心愿，当即出现两道神光。惟愿疫情消失，别...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>戴口罩很重要在当前疫情防控形势下，戴口罩依然是公众做好个人防护的重要手段！戴好口罩到底能在多...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>昨天有个省区市出现病例，前一日是个。总数升至100。广西疫情重点在崇左。甘肃疫情重点在临夏州...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>今天下班时间凌晨50，走在路上好冷，感觉冬天要来了。气候的反常，疫情的反常，活着就好！今年的...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25423</th>\n      <td>1</td>\n      <td>深圳疫情防控疫情退</td>\n    </tr>\n    <tr>\n      <th>25424</th>\n      <td>1</td>\n      <td>最近很多人都受到了感染，感染后的症状轻重各别，有些人觉得比较轻松就度过去了，有些人却经历了高...</td>\n    </tr>\n    <tr>\n      <th>25425</th>\n      <td>1</td>\n      <td>快递驿站站长，武汉疫情期间的送菜英雄，同时他还收养了0多只流浪猫。春节期间他的快递驿站不打烊...</td>\n    </tr>\n    <tr>\n      <th>25426</th>\n      <td>1</td>\n      <td>懒觉疫情刮红赛</td>\n    </tr>\n    <tr>\n      <th>25427</th>\n      <td>1</td>\n      <td>三年前快过年的时候正赶上武汉疫情兴起武汉封城，很多人逃到岳阳。当时一家子的人都笑我说我紧张兮...</td>\n    </tr>\n  </tbody>\n</table>\n<p>25428 rows × 2 columns</p>\n</div>"},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"       label                                             review\n17900      0                               郑州疫情天了，又冒一个，无尽的从头开始算\n29481      0  疫情开放到现在。有没有媒体去各大医院采访调查过真实的医疗挤兑和新冠病患情况呢？感觉比想像中的...\n22834      0  官方回应重庆核酸志愿者是混阳消息不实在如今疫情管控之下可能会出现一些问题，但可能出现的问题和...\n6936       0          我0号去了望丛祠号去了三道堰现在很慌郫都区疫情应该确诊的病例没有那么早去过吧阆中市\n18840      0                                         真想念没有疫情的夏天\n...      ...                                                ...\n22177      1  杭锦后旗关于公布例阳性感染者行程轨迹的通告疫情速报众志成城抗击疫情巴彦淖尔身边事巴彦淖尔日报...\n8778       1                                  看到的热帖疫情之下，0岁人生感悟。\n19359      1  广州市人民政府新闻办公室定于月5日星期六上午11000，召开广州市疫情防控新闻发布会20年总...\n2250       1  致敬疫情前线医护人员现在是北京时间凌晨59分，核酸采集途径高速路口，看到高速路口的核酸采集值...\n21416      1                            希望疫情早日结束。想回家撒撒娇想见外公外婆……\n\n[23266 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17900</th>\n      <td>0</td>\n      <td>郑州疫情天了，又冒一个，无尽的从头开始算</td>\n    </tr>\n    <tr>\n      <th>29481</th>\n      <td>0</td>\n      <td>疫情开放到现在。有没有媒体去各大医院采访调查过真实的医疗挤兑和新冠病患情况呢？感觉比想像中的...</td>\n    </tr>\n    <tr>\n      <th>22834</th>\n      <td>0</td>\n      <td>官方回应重庆核酸志愿者是混阳消息不实在如今疫情管控之下可能会出现一些问题，但可能出现的问题和...</td>\n    </tr>\n    <tr>\n      <th>6936</th>\n      <td>0</td>\n      <td>我0号去了望丛祠号去了三道堰现在很慌郫都区疫情应该确诊的病例没有那么早去过吧阆中市</td>\n    </tr>\n    <tr>\n      <th>18840</th>\n      <td>0</td>\n      <td>真想念没有疫情的夏天</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>22177</th>\n      <td>1</td>\n      <td>杭锦后旗关于公布例阳性感染者行程轨迹的通告疫情速报众志成城抗击疫情巴彦淖尔身边事巴彦淖尔日报...</td>\n    </tr>\n    <tr>\n      <th>8778</th>\n      <td>1</td>\n      <td>看到的热帖疫情之下，0岁人生感悟。</td>\n    </tr>\n    <tr>\n      <th>19359</th>\n      <td>1</td>\n      <td>广州市人民政府新闻办公室定于月5日星期六上午11000，召开广州市疫情防控新闻发布会20年总...</td>\n    </tr>\n    <tr>\n      <th>2250</th>\n      <td>1</td>\n      <td>致敬疫情前线医护人员现在是北京时间凌晨59分，核酸采集途径高速路口，看到高速路口的核酸采集值...</td>\n    </tr>\n    <tr>\n      <th>21416</th>\n      <td>1</td>\n      <td>希望疫情早日结束。想回家撒撒娇想见外公外婆……</td>\n    </tr>\n  </tbody>\n</table>\n<p>23266 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport numpy as np\nimport torchvision\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils import data\nfrom torchvision import transforms\nfrom torchinfo import summary\nimport collections\nfrom transformers import AutoTokenizer, DataCollatorWithPadding","metadata":{"execution":{"iopub.status.busy":"2023-11-07T07:51:57.163750Z","iopub.execute_input":"2023-11-07T07:51:57.164137Z","iopub.status.idle":"2023-11-07T07:52:04.571116Z","shell.execute_reply.started":"2023-11-07T07:51:57.164110Z","shell.execute_reply":"2023-11-07T07:52:04.570171Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"batch_size = 32#超参数，批量大小\nmax_length = 64#超参数，最大长度\ntokenizer = AutoTokenizer.from_pretrained('hfl/chinese-roberta-wwm-ext')#加载分词器","metadata":{"execution":{"iopub.status.busy":"2023-11-07T07:52:04.572580Z","iopub.execute_input":"2023-11-07T07:52:04.573190Z","iopub.status.idle":"2023-11-07T07:52:07.344452Z","shell.execute_reply.started":"2023-11-07T07:52:04.573160Z","shell.execute_reply":"2023-11-07T07:52:07.343524Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/19.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f193d72cf3b74e78b97752dab329e0b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a26fcd6eefd454991e43babb550179b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d6ccacd8e794020ba1ba8324df6b188"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/269k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79d6d239ecdb44dd8cc2bbf67cb7f490"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa009de2a2a34a03a1dd84041ce3af68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dd049e7eb43430abe06b367b09652b3"}},"metadata":{}}]},{"cell_type":"code","source":"cuda = True\ndevice = \"cuda\" if cuda else cpu","metadata":{"execution":{"iopub.status.busy":"2023-11-07T07:52:07.345827Z","iopub.execute_input":"2023-11-07T07:52:07.346542Z","iopub.status.idle":"2023-11-07T07:52:07.350683Z","shell.execute_reply.started":"2023-11-07T07:52:07.346506Z","shell.execute_reply":"2023-11-07T07:52:07.349784Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def get_data_loaders(data, tokenizer, batch_size, max_length, shuffle = True):#shuffle：需不需要打乱\n    collact = DataCollatorWithPadding(tokenizer)\n    dataset = []\n    texts = data['review'].to_list()#将评论转化列表\n    labels = data['label'].to_list()#将分类列表转化为列表\n    for i in tqdm(range(len(texts))):\n        text, label = texts[i], labels[i]\n        inputs = tokenizer(text = text, max_length = max_length, padding = 'max_length', truncation = True)#truncation是判断超过长度是否截断\n        inputs[\"labels\"] = label\n        dataset.append(inputs)\n    data_loader = DataLoader(dataset, batch_size = batch_size, shuffle = shuffle, collate_fn = collact)\n    return data_loader\n\ntrain_loader = get_data_loaders(train_set, tokenizer, batch_size = batch_size, max_length = max_length)#如果不使用采样操作，则第一个参数为：train_set；如果进行采样的话，则第一个输入为：train_set_balanced\ntest_loader = get_data_loaders(test_set, tokenizer, batch_size * 2, max_length = max_length, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T07:52:07.351893Z","iopub.execute_input":"2023-11-07T07:52:07.352235Z","iopub.status.idle":"2023-11-07T07:52:18.372928Z","shell.execute_reply.started":"2023-11-07T07:52:07.352203Z","shell.execute_reply":"2023-11-07T07:52:18.371871Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"100%|██████████| 24347/24347 [00:08<00:00, 2842.06it/s]\n100%|██████████| 6087/6087 [00:02<00:00, 2502.00it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2023-11-07T07:54:42.157764Z","iopub.execute_input":"2023-11-07T07:54:42.158172Z","iopub.status.idle":"2023-11-07T07:54:42.176084Z","shell.execute_reply.started":"2023-11-07T07:54:42.158142Z","shell.execute_reply":"2023-11-07T07:54:42.175196Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Roberta_wwm_ext_ClassificationModel(nn.Module):\n    def __init__(self, hidden_size, num_classes):\n        super(Roberta_wwm_ext_ClassificationModel, self).__init__()\n        self.pretrained_roberta_wwm_ext = AutoModelForSequenceClassification.from_pretrained('hfl/chinese-roberta-wwm-ext', num_labels=2).to(device)\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        outputs = self.pretrained_roberta_wwm_ext(\n                                                 input_ids = input_ids,\n                                                 attention_mask = attention_mask,\n                                                 token_type_ids = token_type_ids\n                                                 )#需要返回input_ids;attention_mask;token_type_ids\n        logits = outputs.logits#直接拿出outputs中的最后一层\n        return logits","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:01:43.460504Z","iopub.execute_input":"2023-11-07T08:01:43.461196Z","iopub.status.idle":"2023-11-07T08:01:43.467502Z","shell.execute_reply.started":"2023-11-07T08:01:43.461163Z","shell.execute_reply":"2023-11-07T08:01:43.466455Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"roberta_wwm_ext_model = Roberta_wwm_ext_ClassificationModel(hidden_size = 768, num_classes = 2).to(device)\n#输出模型参数\nsummary(roberta_wwm_ext_model)\ntotal = sum ([param.nelement () for param in roberta_wwm_ext_model.parameters ()]) \nprint (\"Number of parameters: %.2fM\" % (total/1e6))","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:01:43.635813Z","iopub.execute_input":"2023-11-07T08:01:43.636079Z","iopub.status.idle":"2023-11-07T08:01:45.348146Z","shell.execute_reply.started":"2023-11-07T08:01:43.636056Z","shell.execute_reply":"2023-11-07T08:01:45.347056Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"=====================================================================================\nLayer (type:depth-idx)                                       Param #\n=====================================================================================\nRoberta_wwm_ext_ClassificationModel                          --\n├─BertForSequenceClassification: 1-1                         --\n│    └─BertModel: 2-1                                        --\n│    │    └─BertEmbeddings: 3-1                              16,622,592\n│    │    └─BertEncoder: 3-2                                 85,054,464\n│    │    └─BertPooler: 3-3                                  590,592\n│    └─Dropout: 2-2                                          --\n│    └─Linear: 2-3                                           1,538\n=====================================================================================\nTotal params: 102,269,186\nTrainable params: 102,269,186\nNon-trainable params: 0\n====================================================================================="},"metadata":{}},{"name":"stdout","text":"Number of parameters: 102.27M\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:01:53.434867Z","iopub.execute_input":"2023-11-07T08:01:53.435645Z","iopub.status.idle":"2023-11-07T08:01:53.440170Z","shell.execute_reply.started":"2023-11-07T08:01:53.435611Z","shell.execute_reply":"2023-11-07T08:01:53.439227Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def roberta_wwm_ext_evaluate_model(net, test_iter, criterion, device = None):\n    \"\"\"\n    net: bert_model\n    data_loader: test_dataloader\n    criterion: CEloss;KLloss\n    device: GPU\n    \"\"\"\n    if isinstance(net, nn.Module):\n        net.eval()\n        if not device:\n            device = next(iter(net.parameters())).device\n    #在测试集上不需要梯度更新，所以这里直接梯度冻结        \n    with torch.no_grad():\n        test_y_all, prediction_all = [], []#用来存储测试集上的真实值和预测值\n        total_loss = 0.0#初始化损失值\n        for test_data in test_iter:\n            test_data = test_data.to(device)#将测试集数据挪到GPU上\n            out = net(\n                     input_ids = test_data[\"input_ids\"],\n                     attention_mask = test_data[\"attention_mask\"],\n                     token_type_ids = test_data[\"token_type_ids\"]\n                     )\n            test_y = test_data[\"labels\"]\n            \n            l = criterion(out, test_y)\n            total_loss += l.sum().item()#计算每个样本的损失\n            \n            prediction = out.argmax(dim = 1)\n            prediction = prediction.cpu().detach().numpy()#将测试集上的预测值从GPU上抽出并转化为list\n            test_y = test_y.cpu().detach().numpy()#将测试集上的真实值从GPU上抽出并转化为list\n            \n            test_y_all.append(test_y)#将真实值进行拼接\n            prediction_all.append(prediction)#将预测值进行拼接\n        \n        test_y_all = np.concatenate(test_y_all, axis=0)#将测试集的真实值按行进行拼接\n        prediction_all = np.concatenate(prediction_all, axis=0)#将测试集的预测值按行进行拼接\n        \n        #设置评价指标\n        acc_score = accuracy_score(test_y_all, prediction_all)#准确率\n        pre_score = precision_score(test_y_all, prediction_all, average = \"binary\")#二分类的精确率\n        rec_score = recall_score(test_y_all, prediction_all, average = \"binary\")#二分类的召回率\n        fscore = f1_score(test_y_all, prediction_all, average = \"binary\")#二分类的f1得分\n        \n        #返回测试集上模型的平均损失\n        avg_loss = total_loss / len(test_iter)\n        \n    #依次返回了acc;pre;rec,f1和loss    \n    return acc_score, pre_score, rec_score, fscore, avg_loss","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:01:54.703442Z","iopub.execute_input":"2023-11-07T08:01:54.703799Z","iopub.status.idle":"2023-11-07T08:01:54.715132Z","shell.execute_reply.started":"2023-11-07T08:01:54.703771Z","shell.execute_reply":"2023-11-07T08:01:54.714220Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"teacher_loss = nn.CrossEntropyLoss()\ntest_acc, test_pre, test_rec, test_f1, test_loss = roberta_wwm_ext_evaluate_model(roberta_wwm_ext_model, test_loader, criterion = teacher_loss)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:01:57.334654Z","iopub.execute_input":"2023-11-07T08:01:57.335027Z","iopub.status.idle":"2023-11-07T08:02:07.957254Z","shell.execute_reply.started":"2023-11-07T08:01:57.334997Z","shell.execute_reply":"2023-11-07T08:02:07.956433Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import time#输出单条数据的推理时间","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:02:09.896815Z","iopub.execute_input":"2023-11-07T08:02:09.897504Z","iopub.status.idle":"2023-11-07T08:02:09.901443Z","shell.execute_reply.started":"2023-11-07T08:02:09.897473Z","shell.execute_reply":"2023-11-07T08:02:09.900538Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def roberta_wwm_ext_model_classification(net, train_iter, criterion, optimizer, num_epochs, device):\n    \"\"\"\n    net: bert_model\n    data_loader: train_dataloader\n    loss: bert_teacher_loss\n    optimizer: bert_teacher_optimizer\n    num_epochs: epoch\n    device: GPU\n    \"\"\"\n    net.train()\n    for epoch in range(num_epochs):\n        timer = d2l.Timer()#设置模型训练时间\n        train_y_all, prediction_all = [], []#用来存储训练数据的真实值和预测值\n        for train_data in tqdm(train_iter):\n            train_data = train_data.to(device)#将训练数据集挪到GPU上\n            \n            start_time = time.time()#计时开始\n            \n            out = net(\n                     input_ids = train_data[\"input_ids\"],\n                     attention_mask = train_data[\"attention_mask\"],\n                     token_type_ids = train_data[\"token_type_ids\"]\n                     )\n            train_y = train_data[\"labels\"]\n            \n            #计算损失\n            loss = criterion(out, train_y)\n            \n            #梯度清除\n            optimizer.zero_grad()\n            #反向传播\n            loss.backward()\n            #梯度更新\n            optimizer.step()\n            \n            prediction = out.argmax(dim = 1)#将训练集上的预测值从logti——>softmax\n            \n            end_time = time.time()\n            inference_time = (end_time - start_time) * 1000#计算单条推理时间，并以毫秒进行显示\n            \n            #将prediction和train_y从GPU中抽到CPU\n            prediction = prediction.cpu().detach()\n            train_y = train_y.cpu().detach()\n            \n            train_y_all.append(train_y)#存储当前epoch中的真实标签\n            prediction_all.append(prediction)#存储当前epoch中的测试值\n        \n        train_y_all = torch.cat(train_y_all, dim = 0)#按行链接所有epoch的真实标签\n        prediction_all = torch.cat(prediction_all, dim = 0)#按行链接所有epoch的预测值\n        #设置模型评价指标    \n        acc_score = accuracy_score(train_y_all,  prediction_all)\n        pre_score = precision_score(train_y_all, prediction_all, average = \"binary\")\n        rec_score = recall_score(train_y_all, prediction_all, average = \"binary\")\n        fscore = f1_score(train_y_all, prediction_all, average = \"binary\")\n        \n        #在训练集上进行模型训练，并输出评价指标和loss    \n        print(f'epoch{epoch+1}, train_loss {loss:.4f}, train_acc {acc_score:.4f}, train_pre {pre_score:.4f}, train_rec {rec_score:.4f}, train_f1 {fscore:.4f}')\n        \n        #在测试集上进行模型评估，并输出评价指标和loss\n        test_acc, test_pre, test_rec, test_f1, test_loss = roberta_wwm_ext_evaluate_model(roberta_wwm_ext_model, test_loader, criterion = teacher_loss)\n        print(f'test loss {test_loss:.4f}', f'test acc {test_acc:.4f}', f'test pre {test_pre:.4f}', f'test rec {test_rec:.4f}', f'test f1 {test_f1:.4f}')\n        \n        #计算模型推理时间；计算出单条数据的推理时间\n        print(\"Total time : {:.2f}\".format(timer.stop()), \"Single_data time: {:.2f} ms\".format(inference_time))","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:02:12.321092Z","iopub.execute_input":"2023-11-07T08:02:12.322068Z","iopub.status.idle":"2023-11-07T08:02:12.334591Z","shell.execute_reply.started":"2023-11-07T08:02:12.322035Z","shell.execute_reply":"2023-11-07T08:02:12.333570Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"lr = 3e-5#学习率：超参数\nnum_epochs = 1#迭代周期：超参数","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:02:15.627089Z","iopub.execute_input":"2023-11-07T08:02:15.627599Z","iopub.status.idle":"2023-11-07T08:02:15.631990Z","shell.execute_reply.started":"2023-11-07T08:02:15.627558Z","shell.execute_reply":"2023-11-07T08:02:15.631066Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"roberta_wwm_ext_model = Roberta_wwm_ext_ClassificationModel(hidden_size = 768, num_classes = 2).to(device)\nteacher_loss = nn.CrossEntropyLoss()\nteacher_optimizer = AdamW(roberta_wwm_ext_model.parameters(), lr=lr)#优化器的选择：超参数","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:02:18.383861Z","iopub.execute_input":"2023-11-07T08:02:18.384475Z","iopub.status.idle":"2023-11-07T08:02:20.211685Z","shell.execute_reply.started":"2023-11-07T08:02:18.384443Z","shell.execute_reply":"2023-11-07T08:02:20.210848Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"electramodel_classification(net = electra_model, train_iter = train_loader, criterion = teacher_loss, optimizer = teacher_optimizer, num_epochs = num_epochs, device = device)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:02:23.237703Z","iopub.execute_input":"2023-11-07T08:02:23.238637Z","iopub.status.idle":"2023-11-07T08:04:46.970501Z","shell.execute_reply.started":"2023-11-07T08:02:23.238603Z","shell.execute_reply":"2023-11-07T08:04:46.969386Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"100%|██████████| 761/761 [02:13<00:00,  5.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch1, train_loss 0.2181, train_acc 0.9450, train_pre 0.9309, train_rec 0.9559, train_f1 0.9432\ntest loss 0.5486 test acc 0.8030 test pre 0.7717 test rec 0.8346 test f1 0.8019\nTotal time : 143.72 Single_data time: 25.92 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(roberta_wwm_ext_model.state_dict(), '/kaggle/working/roberta_wwm_ext_model.pth')#注意保存路径。其中，第一个model的意思是自己定义的模型；第二个model的意思是，保存预训练好的模型的名字","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:09:21.690071Z","iopub.execute_input":"2023-11-07T08:09:21.690465Z","iopub.status.idle":"2023-11-07T08:09:22.205230Z","shell.execute_reply.started":"2023-11-07T08:09:21.690434Z","shell.execute_reply":"2023-11-07T08:09:22.204208Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# 加载保存的BERT模型参数\nroberta_wwm_ext_model = Roberta_wwm_ext_ClassificationModel(hidden_size=768, num_classes=2)\nroberta_wwm_ext_model.load_state_dict(torch.load('/kaggle/working/roberta_wwm_ext_model.pth'))#注意加载路径。其中，第一个model的意思是自己定义的模型；第二个model的意思是，保存预训练好的模型的名字","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:09:32.951722Z","iopub.execute_input":"2023-11-07T08:09:32.952090Z","iopub.status.idle":"2023-11-07T08:09:34.712400Z","shell.execute_reply.started":"2023-11-07T08:09:32.952061Z","shell.execute_reply":"2023-11-07T08:09:34.711454Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"class BiLSTMClassification(nn.Module):\n    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, **kwargs):\n        \"\"\"\n        vocab_size：词汇表的大小\n        embed_size：嵌入层大小embedding_size\n        hiddern_size：隐藏层大小\n        num_layers：层数\n        \"\"\"\n        super(BiLSTMClassification, self).__init__(**kwargs)\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.encoder = nn.LSTM(embed_size, hidden_size, num_layers = num_layers, bidirectional = True, dropout = 0.5)\n        self.decoder = nn.Sequential(\n                                      nn.Linear(2 * hidden_size, 2)#双向LSTM中，先前向一次再后向一次，所以是*2\n                                      )\n    def forward(self, inputs):\n        \"\"\"\n        input_shape: (batch_size, max_length)\n        \"\"\"\n        embeddings = self.embedding(inputs).transpose(0, 1)#shape：(max_length, batch_size, embed_size)#保证max_length在第一个维度\n        outputs, (_,_) = self.encoder(embeddings)#输出为: (outputs, hidden_state)，只取出outputs所对应的向量，舍去hidden_state所对应的向量\n        outputs_fw = outputs[:, :, :hidden_size]#BiLSTM需要拿出前向LSMT的最后一个时间步骤的向量\n        outputs_bw = outputs[:, :, hidden_size:]#BiLSTM需要拿出后向LSTM的第一个时间步骤的向量\n        logits = self.decoder(torch.cat((outputs_fw[-1], outputs_bw[0]), dim = 1))#将最后一个时间步骤的向量和第一个时间步骤的向量进行concat操作\n        return logits","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:09:36.819643Z","iopub.execute_input":"2023-11-07T08:09:36.820508Z","iopub.status.idle":"2023-11-07T08:09:36.829166Z","shell.execute_reply.started":"2023-11-07T08:09:36.820475Z","shell.execute_reply":"2023-11-07T08:09:36.828206Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"vocab_size = tokenizer.get_vocab()\nlen(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:09:38.980410Z","iopub.execute_input":"2023-11-07T08:09:38.980794Z","iopub.status.idle":"2023-11-07T08:09:38.996829Z","shell.execute_reply.started":"2023-11-07T08:09:38.980766Z","shell.execute_reply":"2023-11-07T08:09:38.995893Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"21128"},"metadata":{}}]},{"cell_type":"code","source":"#定义学生模型参数\nembed_size, hidden_size, num_layers = 64, 64, 2\nbilstm_model = BiLSTMClassification(len(vocab_size), embed_size, hidden_size, num_layers).to(device)#vocab_szie = tokenizer.get_vocab()\nsummary(bilstm_model)\ntotal = sum([param.nelement() for param in bilstm_model.parameters()])\nprint(\"Number of parameters: %.2fM\" % (total/1e6))","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:09:41.441546Z","iopub.execute_input":"2023-11-07T08:09:41.441933Z","iopub.status.idle":"2023-11-07T08:09:41.746103Z","shell.execute_reply.started":"2023-11-07T08:09:41.441898Z","shell.execute_reply":"2023-11-07T08:09:41.745068Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nBiLSTMClassification                     --\n├─Embedding: 1-1                         1,352,192\n├─LSTM: 1-2                              165,888\n├─Sequential: 1-3                        --\n│    └─Linear: 2-1                       258\n=================================================================\nTotal params: 1,518,338\nTrainable params: 1,518,338\nNon-trainable params: 0\n================================================================="},"metadata":{}},{"name":"stdout","text":"Number of parameters: 1.52M\n","output_type":"stream"}]},{"cell_type":"code","source":"def bilstm_evaluate_model(net, test_iter, criterion, device = None):\n    \"\"\"\n    net: bert_model\n    data_loader: test_dataloader\n    criterion: CEloss;KLloss\n    device: GPU\n    \"\"\"\n    if isinstance(net, nn.Module):\n        net.eval()\n        if not device:\n            device = next(iter(net.parameters())).device\n    #在测试集上不需要梯度更新，所以这里直接梯度冻结        \n    with torch.no_grad():\n        test_y_all, prediction_all = [], []#用来存储测试集上的真实值和预测值\n        total_loss = 0.0#初始化损失值\n        for test_data in test_iter:\n            test_data = test_data.to(device)#将测试集数据挪到GPU上\n            out = net(\n                     inputs = test_data[\"input_ids\"]\n                     )\n            test_y = test_data[\"labels\"]\n            \n            l = criterion(out, test_y)\n            total_loss += l.sum().item()#计算每个样本的损失\n            \n            prediction = out.argmax(dim = 1)\n            prediction = prediction.cpu().detach().numpy()#将测试集上的预测值从GPU上抽出并转化为list\n            test_y = test_y.cpu().detach().numpy()#将测试集上的真实值从GPU上抽出并转化为list\n            \n            test_y_all.append(test_y)#将真实值进行拼接\n            prediction_all.append(prediction)#将预测值进行拼接\n        \n        test_y_all = np.concatenate(test_y_all, axis=0)#将测试集的真实值按行进行拼接\n        prediction_all = np.concatenate(prediction_all, axis=0)#将测试集的预测值按行进行拼接\n        \n        #设置评价指标\n        acc_score = accuracy_score(test_y_all, prediction_all)#准确率\n        pre_score = precision_score(test_y_all, prediction_all, average = \"binary\")#二分类的精确率\n        rec_score = recall_score(test_y_all, prediction_all, average = \"binary\")#二分类的召回率\n        fscore = f1_score(test_y_all, prediction_all, average = \"binary\")#二分类的f1得分\n        \n        #返回测试集上模型的平均损失\n        avg_loss = total_loss / len(test_iter)\n        \n    #依次返回了acc;pre;rec,f1和loss    \n    return acc_score, pre_score, rec_score, fscore, avg_loss","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:09:44.523269Z","iopub.execute_input":"2023-11-07T08:09:44.523650Z","iopub.status.idle":"2023-11-07T08:09:44.534241Z","shell.execute_reply.started":"2023-11-07T08:09:44.523619Z","shell.execute_reply":"2023-11-07T08:09:44.533268Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"teacher_loss = nn.CrossEntropyLoss()\ntest_acc, test_pre, test_rec, test_f1, test_loss = bilstm_evaluate_model(bilstm_model, test_loader, criterion = teacher_loss)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:09:52.423232Z","iopub.execute_input":"2023-11-07T08:09:52.424034Z","iopub.status.idle":"2023-11-07T08:09:53.163474Z","shell.execute_reply.started":"2023-11-07T08:09:52.424000Z","shell.execute_reply":"2023-11-07T08:09:53.162603Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def bilstmmodel_classification(net, train_iter, criterion, optimizer, num_epochs, device):\n    \"\"\"\n    net: bilstm_model,学生模型\n    train_iter: train_loader,数据集\n    criterion: bilstm_student_loss,学生模型损失函数\n    optimizer: bilstm_student_optimizer,学生模型优化器\n    num_epoch: student_epoch，学生模型迭代周期\n    device: GPU,加速器\n    \"\"\"\n    for epoch in range(num_epochs):\n        net.train()  # 设置模型为训练模式\n        timer = d2l.Timer()#设置模型训练时间\n        train_y_all, prediction_all = [], []#用来存储训练数据的真实值和预测值\n        for train_data in tqdm(train_iter):\n            train_data = train_data.to(device)#将训练数据集挪到GPU上\n            \n            start_time = time.time()#计时开始\n            \n            out = net(\n                     inputs = train_data[\"input_ids\"]#只需要去除tokenizer中的input_ids即可\n                     )\n            train_y = train_data[\"labels\"]\n            \n            #计算损失\n            loss = criterion(out, train_y)\n            \n            #梯度清除\n            optimizer.zero_grad()\n            #反向传播\n            loss.backward()\n            #梯度更新\n            optimizer.step()\n            \n            prediction = out.argmax(dim = 1)#将训练集上的预测值从logit——>softmax\n            \n            end_time = time.time()\n            inference_time = (end_time - start_time) * 1000#计算单条推理时间，并以毫秒进行显示\n            \n            #将prediction和train_y从GPU中抽到CPU\n            prediction = prediction.cpu().detach()\n            train_y = train_y.cpu().detach()\n            \n            train_y_all.append(train_y)#存储当前epoch中的真实标签\n            prediction_all.append(prediction)#存储当前epoch中的测试值\n        \n        train_y_all = torch.cat(train_y_all, dim = 0)#按行链接所有epoch的真实标签\n        prediction_all = torch.cat(prediction_all, dim = 0)#按行链接所有epoch的预测值\n        #设置模型评价指标    \n        acc_score = accuracy_score(train_y_all,  prediction_all)\n        pre_score = precision_score(train_y_all, prediction_all, average = \"binary\")\n        rec_score = recall_score(train_y_all, prediction_all, average = \"binary\")\n        fscore = f1_score(train_y_all, prediction_all, average = \"binary\")\n        \n        #在训练集上进行模型训练，并输出评价指标和loss    \n        print(f'epoch{epoch+1}, train_loss {loss:.4f}, train_acc {acc_score:.4f}, train_pre {pre_score:.4f}, train_rec {rec_score:.4f}, train_f1 {fscore:.4f}')\n        \n        #在测试集上进行模型评估，并输出评价指标和loss\n        test_acc, test_pre, test_rec, test_f1, test_loss = bilstm_evaluate_model(bilstm_model, test_loader, criterion = student_loss)\n        print(f'test loss {test_loss:.4f}', f'test acc {test_acc:.4f}', f'test pre {test_pre:.4f}', f'test rec {test_rec:.4f}', f'test f1 {test_f1:.4f}')\n        \n        #计算模型推理时间；计算出单条数据的推理时间\n        print(\"Total time : {:.2f}\".format(timer.stop()), \"Single_data time: {:.2f} ms\".format(inference_time))","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:10:06.800446Z","iopub.execute_input":"2023-11-07T08:10:06.801200Z","iopub.status.idle":"2023-11-07T08:10:06.813602Z","shell.execute_reply.started":"2023-11-07T08:10:06.801169Z","shell.execute_reply":"2023-11-07T08:10:06.812621Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"lr = 0.0001#学习率：超参数\nnum_epochs = 3#迭代周期：超参数","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:10:10.251892Z","iopub.execute_input":"2023-11-07T08:10:10.252747Z","iopub.status.idle":"2023-11-07T08:10:10.256847Z","shell.execute_reply.started":"2023-11-07T08:10:10.252712Z","shell.execute_reply":"2023-11-07T08:10:10.255856Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"bilstm_model = BiLSTMClassification(len(vocab_size), embed_size, hidden_size, num_layers).to(device)#vocab_szie = tokenizer.get_vocab()\nstudent_loss = nn.CrossEntropyLoss()\nstudent_optimizer = AdamW(bilstm_model.parameters(), lr=lr)#优化器的选择：超参数","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:10:12.453941Z","iopub.execute_input":"2023-11-07T08:10:12.454298Z","iopub.status.idle":"2023-11-07T08:10:12.474325Z","shell.execute_reply.started":"2023-11-07T08:10:12.454270Z","shell.execute_reply":"2023-11-07T08:10:12.473581Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"bilstmmodel_classification(bilstm_model, train_loader, criterion = student_loss, optimizer = student_optimizer, num_epochs = num_epochs, device = device)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:10:15.024694Z","iopub.execute_input":"2023-11-07T08:10:15.025840Z","iopub.status.idle":"2023-11-07T08:10:29.776338Z","shell.execute_reply.started":"2023-11-07T08:10:15.025796Z","shell.execute_reply":"2023-11-07T08:10:29.775436Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"100%|██████████| 761/761 [00:04<00:00, 171.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch1, train_loss 0.6533, train_acc 0.5705, train_pre 0.5575, train_rec 0.4900, train_f1 0.5216\ntest loss 0.6445 test acc 0.6279 test pre 0.6257 test rec 0.5502 test f1 0.5855\nTotal time : 5.06 Single_data time: 2.78 ms\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 761/761 [00:04<00:00, 180.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch2, train_loss 0.4264, train_acc 0.6878, train_pre 0.6826, train_rec 0.6479, train_f1 0.6648\ntest loss 0.5688 test acc 0.7048 test pre 0.6850 test rec 0.7074 test f1 0.6960\nTotal time : 4.82 Single_data time: 2.94 ms\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 761/761 [00:04<00:00, 178.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch3, train_loss 0.5561, train_acc 0.7262, train_pre 0.7316, train_rec 0.6742, train_f1 0.7017\ntest loss 0.5429 test acc 0.7289 test pre 0.7352 test rec 0.6761 test f1 0.7044\nTotal time : 4.87 Single_data time: 2.82 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"def kd_evaluate_model(teacher_net, student_net, test_iter, hard_loss, soft_loss, device = None):\n    \"\"\"\n    net: bert_model\n    data_loader: test_dataloader\n    criterion: CEloss;KLloss\n    device: GPU\n    \"\"\"\n    if isinstance(student_net, nn.Module):\n        teacher_net.eval()\n        student_net.eval()\n        if not device:\n            device = next(iter(student_net.parameters())).device\n    #在测试集上不需要梯度更新，所以这里直接梯度冻结        \n    with torch.no_grad():\n        test_y_all, student_prediction_all = [], []#用来存储测试集上的真实值和预测值\n        total_loss = 0.0#初始化损失值\n        for test_data in test_iter:\n            test_data = test_data.to(device)#将测试集数据挪到GPU上\n            teacher_out = teacher_net(\n                                     input_ids = test_data[\"input_ids\"],\n                                     attention_mask = test_data[\"attention_mask\"],\n                                     token_type_ids = test_data[\"token_type_ids\"]\n                                     )\n            student_out = student_net(\n                                     inputs = test_data[\"input_ids\"]\n                                     )\n            test_y = test_data[\"labels\"]\n            student_loss = hard_loss(student_out, test_y)\n            dist_loss = soft_loss(\n                                 F.log_softmax(student_out / T, dim = -1),\n                                 F.softmax(teacher_out / T, dim = -1)\n                                 )\n            total_loss = (1 - alpha) * student_loss + alpha * dist_loss\n            total_loss += total_loss.sum().item()#计算每个样本的损失\n            \n            student_prediction = student_out.argmax(dim = 1)\n            student_prediction = student_prediction.cpu().detach().numpy()#将测试集上的预测值从GPU上抽出并转化为list\n            test_y = test_y.cpu().detach().numpy()#将测试集上的真实值从GPU上抽出并转化为list\n            \n            test_y_all.append(test_y)#将真实值进行拼接\n            student_prediction_all.append(student_prediction)#将预测值进行拼接\n        \n        test_y_all = np.concatenate(test_y_all, axis=0)#将测试集的真实值按行进行拼接\n        student_prediction_all = np.concatenate(student_prediction_all, axis=0)#将测试集的预测值按行进行拼接\n        \n        #设置评价指标\n        acc_score = accuracy_score(test_y_all, student_prediction_all)#准确率\n        pre_score = precision_score(test_y_all, student_prediction_all, average = \"binary\")#二分类的精确率\n        rec_score = recall_score(test_y_all, student_prediction_all, average = \"binary\")#二分类的召回率\n        fscore = f1_score(test_y_all, student_prediction_all, average = \"binary\")#二分类的f1得分\n        \n        #返回测试集上模型的平均损失\n        avg_loss = total_loss / len(test_iter)\n        \n    #依次返回了acc;pre;rec,f1和loss    \n    return acc_score, pre_score, rec_score, fscore, avg_loss","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:12:25.327762Z","iopub.execute_input":"2023-11-07T08:12:25.328158Z","iopub.status.idle":"2023-11-07T08:12:25.341125Z","shell.execute_reply.started":"2023-11-07T08:12:25.328129Z","shell.execute_reply":"2023-11-07T08:12:25.340166Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"kd_lr = 0.001\nkd_num_epochs = 3\nteacher_model = roberta_wwm_ext_model.to(device)\nstudent_model = bilstm_model.to(device)\nkd_hard_loss = nn.CrossEntropyLoss()\nkd_soft_loss = nn.KLDivLoss(reduction = 'batchmean')\nkd_optimizer = torch.optim.Adam(student_model.parameters(), lr = kd_lr)#优化器的选择：超参数\nT, alpha = 2, 0.8","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:12:28.937143Z","iopub.execute_input":"2023-11-07T08:12:28.937871Z","iopub.status.idle":"2023-11-07T08:12:28.949287Z","shell.execute_reply.started":"2023-11-07T08:12:28.937839Z","shell.execute_reply":"2023-11-07T08:12:28.948444Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"test_acc, test_pre, test_rec, test_f1, test_loss = kd_evaluate_model(teacher_net = roberta_wwm_ext_model, student_net = student_model, test_iter = test_loader, hard_loss = kd_hard_loss, soft_loss = kd_soft_loss)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:12:31.318750Z","iopub.execute_input":"2023-11-07T08:12:31.319105Z","iopub.status.idle":"2023-11-07T08:12:42.039304Z","shell.execute_reply.started":"2023-11-07T08:12:31.319076Z","shell.execute_reply":"2023-11-07T08:12:42.038226Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def kd_blk(teacher_net, student_net, train_iter, hard_loss, soft_loss, optimizer, T, alpha, num_epochs, device):\n    \"\"\"\n    teacher_net: 教师模型\n    student_net: 学生模型\n    train_iter: 训练集迭代器\n    hard_loss, soft_loss: 硬损失，软损失\n    T, alpha, num_epochs: 蒸馏温度， 蒸馏系数， 迭代次数\n    \"\"\"\n    student_net = nn.DataParallel(student_net).to(device)#使用多GPU进行并行训练教师模型\n    teacher_net = nn.DataParallel(teacher_net).to(device)#使用多GPU进行并行训练学生模型\n    teacher_net.eval()#蒸馏过程中，教师模型参数固定\n    for epoch in range(num_epochs):\n        timer = d2l.Timer()#设置模型参数训练时间\n        student_net.train()#设置学生模型为训练模型\n        train_y_all, student_prediction_all = [], []#用来存储训练数据的真实值和预测值\n        for train_data in tqdm(train_iter):\n            train_data = train_data.to(device)#将训练数据集挪到GPU上\n            \n            start_time = time.time()#计时开始\n            \n            #关闭教师模型梯度，使得教师模型不参与梯度更新\n            with torch.no_grad():\n                #输出教师模型的预测值\n                teacher_pre = teacher_net(\n                                         input_ids = train_data[\"input_ids\"],\n                                         attention_mask = train_data[\"attention_mask\"],\n                                         token_type_ids = train_data[\"token_type_ids\"]\n                                         )\n            #输出学生模型的预测值\n            student_pre = student_net(\n                                     inputs = train_data[\"input_ids\"]\n                                     )\n            #输出真实值\n            train_y = train_data[\"labels\"]\n            \n            #计算硬损失（学生损失）\n            student_loss = hard_loss(student_pre, train_y)\n            #计算软损失（蒸馏损失）\n            dist_loss = soft_loss(F.log_softmax(student_pre / T, dim = -1),\n                                  F.softmax(teacher_pre / T, dim = -1)\n                                 )\n            #计算总损失\n            total_loss = (1 - alpha) * student_loss + alpha * dist_loss\n            \n            #梯度清除\n            optimizer.zero_grad()\n            #反向传播\n            total_loss.backward()\n            #梯度更新\n            optimizer.step()\n            \n            #学生模型用来预测\n            student_prediction = student_pre.argmax(dim = 1)#将训练集上的预测值logit——>softmax\n            \n            end_time = time.time()\n            inference_time = (end_time - start_time) * 1000#计算单条推理时间，并以毫秒显示\n            \n            #将student_prediction和train_y从GPU中抽到CPU\n            student_prediction = student_prediction.cpu().detach()\n            train_y = train_y.cpu().detach()\n            \n            train_y_all.append(train_y)#存储当前epoch中的真实标签\n            student_prediction_all.append(student_prediction)#存储当前epoch中的学生模型的预测值\n            \n        train_y_all = torch.cat(train_y_all, dim = 0)#按行链接所有epoch的真实标签\n        student_prediction_all = torch.cat(student_prediction_all, dim = 0)#按行链接所有epoch的学生预测值\n        \n        #设置评价指标\n        acc_score = accuracy_score(train_y_all,  student_prediction_all)\n        pre_score = precision_score(train_y_all, student_prediction_all, average = \"binary\")\n        rec_score = recall_score(train_y_all, student_prediction_all, average = \"binary\")\n        fscore = f1_score(train_y_all, student_prediction_all, average = \"binary\")   \n        \n        #在训练集上进行模型训练，并输出评价指标和loss\n        print(f'epoch{epoch+1}, train_loss {total_loss:.4f}, train acc {acc_score:.4f}, train pre {pre_score:.4f}, train rec {rec_score:.4f}, train f1 {fscore:.4f}')\n        \n        #在测试集上进行模型评估，并输出评价指标和loss\n        test_acc, test_pre, test_rec, test_f1, test_loss = kd_evaluate_model(teacher_net = roberta_wwm_ext_model, student_net = student_model, test_iter = test_loader, hard_loss = kd_hard_loss, soft_loss = kd_soft_loss)\n        print(f'test loss {test_loss:.4f}', f'test acc {test_acc:.4f}', f'test pre {test_pre:.4f}', f'test rec {test_rec:.4f}', f'test f1 {test_f1:.4f}')\n        \n        #计算模型推理时间，计算出单条数据的推理时间\n        print(\"Total time : {:.2f}\".format(timer.stop()), \"Single_data time: {:.2f} ms\".format(inference_time))","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:12:45.562486Z","iopub.execute_input":"2023-11-07T08:12:45.562929Z","iopub.status.idle":"2023-11-07T08:12:45.580838Z","shell.execute_reply.started":"2023-11-07T08:12:45.562891Z","shell.execute_reply":"2023-11-07T08:12:45.579788Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"kd_lr = 0.001\nkd_num_epochs = 3","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:12:55.386950Z","iopub.execute_input":"2023-11-07T08:12:55.387296Z","iopub.status.idle":"2023-11-07T08:12:55.391829Z","shell.execute_reply.started":"2023-11-07T08:12:55.387267Z","shell.execute_reply":"2023-11-07T08:12:55.390758Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"teacher_model = roberta_wwm_ext_model.to(device)\nstudent_model = bilstm_model.to(device)\nkd_hard_loss = nn.CrossEntropyLoss()\nkd_soft_loss = nn.KLDivLoss(reduction = 'batchmean')\nkd_optimizer = torch.optim.Adam(student_model.parameters(), lr = kd_lr)#优化器的选择：超参数\nT, alpha = 2, 0.8","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:12:58.072258Z","iopub.execute_input":"2023-11-07T08:12:58.072628Z","iopub.status.idle":"2023-11-07T08:12:58.083583Z","shell.execute_reply.started":"2023-11-07T08:12:58.072600Z","shell.execute_reply":"2023-11-07T08:12:58.082698Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"kd_blk(teacher_net = teacher_model, student_net = student_model, train_iter = train_loader, hard_loss = kd_hard_loss, soft_loss = kd_soft_loss, optimizer = kd_optimizer, T = T, alpha = alpha, num_epochs = kd_num_epochs, device = device)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T08:13:00.426881Z","iopub.execute_input":"2023-11-07T08:13:00.427561Z","iopub.status.idle":"2023-11-07T08:20:20.644155Z","shell.execute_reply.started":"2023-11-07T08:13:00.427529Z","shell.execute_reply":"2023-11-07T08:20:20.643124Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"100%|██████████| 761/761 [02:15<00:00,  5.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch1, train_loss 0.1167, train acc 0.6582, train pre 0.8639, train rec 0.3377, train f1 0.4856\ntest loss 0.0037 test acc 0.6571 test pre 0.8943 test rec 0.3202 test f1 0.4715\nTotal time : 146.63 Single_data time: 31.27 ms\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 761/761 [02:15<00:00,  5.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch2, train_loss 0.1305, train acc 0.7136, train pre 0.8964, train rec 0.4528, train f1 0.6017\ntest loss 0.0033 test acc 0.7503 test pre 0.8155 test rec 0.6169 test f1 0.7024\nTotal time : 146.75 Single_data time: 32.25 ms\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 761/761 [02:16<00:00,  5.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch3, train_loss 0.1454, train acc 0.7461, train pre 0.9053, train rec 0.5234, train f1 0.6633\ntest loss 0.0037 test acc 0.7639 test pre 0.8219 test rec 0.6458 test f1 0.7233\nTotal time : 146.83 Single_data time: 31.79 ms\n","output_type":"stream"}]}]}